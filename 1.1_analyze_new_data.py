# 1.2_deep_analysis.py –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
import os
import json
import zipfile
import pandas as pd
from pathlib import Path
import re


def deep_analyze_data():
    """–ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–º –ø–∞—Ä—Å–∏–Ω–≥–æ–º"""
    base_path = r"C:\PythonProjects\hahaton_vswm_obji_tresh\–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ\–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ\–í—ã–≥—Ä—É–∑–∫–∞"

    print("üîç –ì–õ–£–ë–û–ö–ò–ô –ê–ù–ê–õ–ò–ó –î–ê–ù–ù–´–•")
    print("=" * 50)

    # –£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –∏–º–µ–Ω —Ñ–∞–π–ª–æ–≤
    def parse_filename(filename):
        """–ü–∞—Ä—Å–∏–º –∏–º—è —Ñ–∞–π–ª–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
        # –£–±–∏—Ä–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
        name_without_ext = Path(filename).stem

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –æ–±—ä–µ–∫—Ç–∞
        if '–Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ' in name_without_ext or '–Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ' in name_without_ext:
            obj_type = "non_compliant_buildings"
        elif '—Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω–∞—è –ø–ª–æ—â–∞–¥–∫–∞' in name_without_ext.lower():
            obj_type = "construction_site"
        else:
            obj_type = "unknown"

        # –ò—â–µ–º –∫–æ–¥ –æ–±—ä–µ–∫—Ç–∞ (00-022, 18-001)
        code_match = re.search(r'(\d{2}-\d{3})', name_without_ext)
        obj_code = code_match.group(1) if code_match else "unknown"

        # –ò—â–µ–º –º–µ—Å—è—Ü
        months = ['—è–Ω–≤–∞—Ä—å', '—Ñ–µ–≤—Ä–∞–ª—å', '–º–∞—Ä—Ç', '–∞–ø—Ä–µ–ª—å', '–º–∞–π', '–∏—é–Ω—å',
                  '–∏—é–ª—å', '–∞–≤–≥—É—Å—Ç', '—Å–µ–Ω—Ç—è–±—Ä—å', '–æ–∫—Ç—è–±—Ä—å', '–Ω–æ—è–±—Ä—å', '–¥–µ–∫–∞–±—Ä—å']
        month = "unknown"
        for m in months:
            if m in name_without_ext.lower():
                month = m
                break

        return obj_type, obj_code, month

    # –°–æ–±–∏—Ä–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
    detailed_analysis = []

    for root, dirs, files in os.walk(base_path):
        for file in files:
            file_path = os.path.join(root, file)

            obj_type, obj_code, month = parse_filename(file)
            file_ext = Path(file).suffix.lower()
            file_size_mb = os.path.getsize(file_path) / (1024 * 1024)

            detailed_analysis.append({
                'filename': file,
                'full_path': file_path,
                'object_type': obj_type,
                'object_code': obj_code,
                'month': month,
                'extension': file_ext,
                'size_mb': round(file_size_mb, 2),
                'file_category': 'archive' if file_ext == '.zip' else
                'metadata' if file_ext == '.json' else
                'additional' if file_ext == '.xlsx' else 'other'
            })

    df = pd.DataFrame(detailed_analysis)

    print("üìä –î–ï–¢–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"–í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {len(df)}")
    print(f"–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {df['size_mb'].sum():.2f} MB")

    # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Ç–∏–ø–∞–º –æ–±—ä–µ–∫—Ç–æ–≤
    print("\nüèóÔ∏è –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–û –¢–ò–ü–ê–ú –û–ë–™–ï–ö–¢–û–í:")
    obj_stats = df.groupby('object_type').agg({
        'filename': 'count',
        'size_mb': 'sum'
    }).round(2)
    print(obj_stats)

    return df


def extract_detailed_json_metadata():
    """–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ JSON –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö"""
    print("\nüîç –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó JSON –ú–ï–¢–ê–î–ê–ù–ù–´–•")
    print("=" * 50)

    base_path = r"C:\PythonProjects\hahaton_vswm_obji_tresh\–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ\–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ\–í—ã–≥—Ä—É–∑–∫–∞"
    json_files = list(Path(base_path).rglob('*.json'))

    metadata_details = []

    for json_file in json_files:
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            print(f"\nüìÑ –§–∞–π–ª: {json_file.name}")
            print(
                f"üìÅ –¢–∏–ø –æ–±—ä–µ–∫—Ç–∞: {'non_compliant_buildings' if '–Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ' in json_file.name else 'construction_site'}")

            if isinstance(data, dict):
                print("üîë –ö–ª—é—á–∏ JSON:")
                for key, value in data.items():
                    if isinstance(value, list):
                        print(f"   {key}: —Å–ø–∏—Å–æ–∫ –∏–∑ {len(value)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
                        # –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–≤—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –µ—Å–ª–∏ —ç—Ç–æ —Å–ø–∏—Å–æ–∫
                        if value and isinstance(value[0], dict):
                            print(f"     –ü—Ä–∏–º–µ—Ä –∫–ª—é—á–µ–π —ç–ª–µ–º–µ–Ω—Ç–∞: {list(value[0].keys())[:5]}")
                    else:
                        print(f"   {key}: {str(value)[:100]}...")

            elif isinstance(data, list):
                print(f"üìã JSON —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–ø–∏—Å–æ–∫ –∏–∑ {len(data)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
                if data and isinstance(data[0], dict):
                    print(f"üîë –ö–ª—é—á–∏ —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {list(data[0].keys())}")

            metadata_details.append({
                'file': json_file.name,
                'data_type': type(data).__name__,
                'size': len(data) if isinstance(data, list) else len(data.keys()) if isinstance(data, dict) else 1,
                'sample': data[0] if isinstance(data, list) and data else list(data.keys())[:3] if isinstance(data,
                                                                                                              dict) else data
            })

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {json_file.name}: {e}")

    return metadata_details


def analyze_zip_contents():
    """–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ ZIP –∞—Ä—Ö–∏–≤–æ–≤"""
    print("\nüì¶ –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó ZIP –ê–†–•–ò–í–û–í")
    print("=" * 50)

    base_path = r"C:\PythonProjects\hahaton_vswm_obji_tresh\–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ\–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ\–í—ã–≥—Ä—É–∑–∫–∞"
    zip_files = list(Path(base_path).rglob('*.zip'))

    zip_analysis = []

    for zip_file in zip_files:
        try:
            with zipfile.ZipFile(zip_file, 'r') as zip_ref:
                all_files = zip_ref.namelist()
                image_files = [f for f in all_files if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
                other_files = [f for f in all_files if not f.lower().endswith(('.jpg', '.jpeg', '.png'))]

                # –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø–∞–ø–æ–∫ –≤–Ω—É—Ç—Ä–∏ –∞—Ä—Ö–∏–≤–∞
                folders = set()
                for file in all_files:
                    folder = os.path.dirname(file)
                    if folder:
                        folders.add(folder)

                print(f"\nüìÅ –ê—Ä—Ö–∏–≤: {zip_file.name}")
                print(f"   üìä –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {len(all_files)}")
                print(f"   üñºÔ∏è  –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(image_files)}")
                print(f"   üìÑ –î—Ä—É–≥–∏—Ö —Ñ–∞–π–ª–æ–≤: {len(other_files)}")
                print(f"   üìÇ –ü–∞–ø–æ–∫ –≤–Ω—É—Ç—Ä–∏: {len(folders)}")

                if folders:
                    print(f"   –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–ø–æ–∫: {list(folders)[:3]}...")

                # –ê–Ω–∞–ª–∏–∑ –∏–º–µ–Ω –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                if image_files:
                    sample_images = image_files[:3]
                    print(f"   –ü—Ä–∏–º–µ—Ä—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:")
                    for img in sample_images:
                        print(f"     - {os.path.basename(img)}")

                zip_analysis.append({
                    'archive_name': zip_file.name,
                    'total_files': len(all_files),
                    'image_count': len(image_files),
                    'folder_count': len(folders),
                    'folder_sample': list(folders)[:3] if folders else [],
                    'image_sample': [os.path.basename(img) for img in image_files[:2]]
                })

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∞—Ä—Ö–∏–≤–∞ {zip_file.name}: {e}")

    return zip_analysis


def extract_sample_images_from_zip():
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
    print("\nüñºÔ∏è  –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –ü–†–ò–ú–ï–†–û–í –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô")
    print("=" * 50)

    base_path = r"C:\PythonProjects\hahaton_vswm_obji_tresh\–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ\–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ\–í—ã–≥—Ä—É–∑–∫–∞"
    zip_files = list(Path(base_path).rglob('*.zip'))

    extract_path = r"C:\PythonProjects\hahaton_vswm_obji_tresh\sample_images"
    os.makedirs(extract_path, exist_ok=True)

    for zip_file in zip_files[:2]:  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 2 –∞—Ä—Ö–∏–≤–∞ –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
        try:
            print(f"\nüì¶ –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –∏–∑: {zip_file.name}")

            with zipfile.ZipFile(zip_file, 'r') as zip_ref:
                image_files = [f for f in zip_ref.namelist() if f.lower().endswith(('.jpg', '.jpeg', '.png'))]

                # –ò–∑–≤–ª–µ–∫–∞–µ–º 3 —Å–ª—É—á–∞–π–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                sample_images = image_files[:3]
                for img_path in sample_images:
                    try:
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤ –ø–æ–¥–ø–∞–ø–∫—É –ø–æ –∏–º–µ–Ω–∏ –∞—Ä—Ö–∏–≤–∞
                        archive_name = Path(zip_file).stem
                        target_dir = os.path.join(extract_path, archive_name)
                        os.makedirs(target_dir, exist_ok=True)

                        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–∞–π–ª
                        zip_ref.extract(img_path, target_dir)
                        extracted_path = os.path.join(target_dir, img_path)

                        print(f"   ‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ: {os.path.basename(img_path)}")

                    except Exception as e:
                        print(f"   ‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è {img_path}: {e}")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞–±–æ—Ç—ã —Å –∞—Ä—Ö–∏–≤–æ–º {zip_file.name}: {e}")


def generate_integration_plan(df, metadata_details, zip_analysis):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–ª–∞–Ω–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Å–∏—Å—Ç–µ–º–æ–π"""
    print("\nüìã –ü–õ–ê–ù –ò–ù–¢–ï–ì–†–ê–¶–ò–ò –° –°–£–©–ï–°–¢–í–£–Æ–©–ï–ô –°–ò–°–¢–ï–ú–û–ô")
    print("=" * 60)

    total_images = sum([z['image_count'] for z in zip_analysis])

    print(f"üéØ –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –î–õ–Ø –ò–ù–¢–ï–ì–†–ê–¶–ò–ò:")
    print(f"   ‚Ä¢ –í—Å–µ–≥–æ –∞—Ä—Ö–∏–≤–æ–≤: {len(zip_analysis)}")
    print(f"   ‚Ä¢ –í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {total_images}")
    print(
        f"   ‚Ä¢ –û–±—ä–µ–∫—Ç—ã –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏: {len([z for z in zip_analysis if '–Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ' in z['archive_name']])} –∞—Ä—Ö–∏–≤–æ–≤")
    print(
        f"   ‚Ä¢ –°—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–µ –ø–ª–æ—â–∞–¥–∫–∏: {len([z for z in zip_analysis if '—Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω–∞—è' in z['archive_name'].lower()])} –∞—Ä—Ö–∏–≤–æ–≤")

    print(f"\nüöÄ –≠–¢–ê–ü–´ –ò–ù–¢–ï–ì–†–ê–¶–ò–ò:")
    print(f"1. üì¶ –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∞—Ä—Ö–∏–≤–æ–≤ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞–ø–∫–∏")
    print(f"2. üîó –°–≤—è–∑—ã–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏–∑ JSON")
    print(f"3. üóÉÔ∏è  –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –Ω–æ–≤—ã–º–∏ —Ç–∞–±–ª–∏—Ü–∞–º–∏")
    print(f"4. ü§ñ –î–æ–æ–±—É—á–µ–Ω–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –Ω–∞ –Ω–æ–≤—ã—Ö —Ç–∏–ø–∞—Ö –æ–±—ä–µ–∫—Ç–æ–≤")
    print(f"5. üåê –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º")

    print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    print(f"   ‚Ä¢ –°–æ–∑–¥–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–µ –ø–∞–ø–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ –æ–±—ä–µ–∫—Ç–æ–≤")
    print(f"   ‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–æ–¥—ã –æ–±—ä–µ–∫—Ç–æ–≤ (00-022, 18-001) –¥–ª—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏")
    print(f"   ‚Ä¢ –î–æ–±–∞–≤–∏—Ç—å –ø–æ–ª—è –¥–ª—è –º–µ—Å—è—Ü–∞ –∏ —Ç–∏–ø–∞ –Ω–∞—Ä—É—à–µ–Ω–∏—è –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö")
    print(f"   ‚Ä¢ –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ —Ç–∏–ø–∞–º –æ–±—ä–µ–∫—Ç–æ–≤")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    print("üöÄ –ó–ê–ü–£–°–ö –ì–õ–£–ë–û–ö–û–ì–û –ê–ù–ê–õ–ò–ó–ê –î–ê–ù–ù–´–• –•–ê–ö–ê–¢–û–ù–ê")
    print("=" * 60)

    # 1. –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
    df = deep_analyze_data()

    # 2. –ê–Ω–∞–ª–∏–∑ JSON –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
    metadata_details = extract_detailed_json_metadata()

    # 3. –ê–Ω–∞–ª–∏–∑ ZIP –∞—Ä—Ö–∏–≤–æ–≤
    zip_analysis = analyze_zip_contents()

    # 4. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    extract_sample_images_from_zip()

    # 5. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–ª–∞–Ω–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
    generate_integration_plan(df, metadata_details, zip_analysis)

    # 6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    output_file = r"C:\PythonProjects\hahaton_vswm_obji_tresh\deep_analysis_report.txt"
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("–û–¢–ß–ï–¢ –ü–û –ì–õ–£–ë–û–ö–û–ú–£ –ê–ù–ê–õ–ò–ó–£ –î–ê–ù–ù–´–•\n")
        f.write("=" * 50 + "\n")
        f.write(f"–í—Å–µ–≥–æ –∞—Ä—Ö–∏–≤–æ–≤: {len(zip_analysis)}\n")
        f.write(f"–í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {sum([z['image_count'] for z in zip_analysis])}\n")
        f.write(f"–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {df['size_mb'].sum():.2f} MB\n")

    print(f"\nüíæ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_file}")
    print("\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω! –ì–æ—Ç–æ–≤–∏–º—Å—è –∫ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏.")


if __name__ == "__main__":
    main()