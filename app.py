import os
import torch
import torch.nn as nn
from PIL import Image
import io
import numpy as np
import cv2
from flask import Flask, request, jsonify

app = Flask(__name__)


def create_compatible_model(state_dict):
    """–°–æ–∑–¥–∞–µ—Ç –º–æ–¥–µ–ª—å, —Å–æ–≤–º–µ—Å—Ç–∏–º—É—é —Å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏"""
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É state_dict —á—Ç–æ–±—ã –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
    has_batchnorm = any('running_mean' in key for key in state_dict.keys())

    print(f"üîç –ê–Ω–∞–ª–∏–∑ –º–æ–¥–µ–ª–∏: BatchNorm = {has_batchnorm}")

    if has_batchnorm:
        # –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å BatchNorm (–¥–ª—è unified_geo_model.pth)
        class UnifiedGeoCNN(nn.Module):
            def __init__(self):
                super().__init__()
                self.features = nn.Sequential(
                    nn.Conv2d(3, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),
                    nn.Conv2d(64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),
                    nn.MaxPool2d(2), nn.Dropout(0.2),

                    nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),
                    nn.Conv2d(128, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),
                    nn.MaxPool2d(2), nn.Dropout(0.3),

                    nn.Conv2d(128, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),
                    nn.Conv2d(256, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),
                    nn.AdaptiveAvgPool2d((7, 7))
                )

                self.regressor = nn.Sequential(
                    nn.Flatten(),
                    nn.Linear(256 * 7 * 7, 1024), nn.BatchNorm1d(1024), nn.ReLU(), nn.Dropout(0.5),
                    nn.Linear(1024, 512), nn.BatchNorm1d(512), nn.ReLU(), nn.Dropout(0.3),
                    nn.Linear(512, 256), nn.ReLU(),
                    nn.Linear(256, 2)
                )

            def forward(self, x):
                x = self.features(x)
                x = self.regressor(x)
                return x

        return UnifiedGeoCNN()

    else:
        # –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –±–µ–∑ BatchNorm (–¥–ª—è final_geo_model.pth)
        class EfficientGeoCNN(nn.Module):
            def __init__(self):
                super().__init__()
                self.features = nn.Sequential(
                    nn.Conv2d(3, 64, 3, padding=1), nn.ReLU(inplace=True),
                    nn.Conv2d(64, 64, 3, padding=1), nn.ReLU(inplace=True),
                    nn.MaxPool2d(2), nn.Dropout(0.2),

                    nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(inplace=True),
                    nn.Conv2d(128, 128, 3, padding=1), nn.ReLU(inplace=True),
                    nn.MaxPool2d(2), nn.Dropout(0.3),

                    nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(inplace=True),
                    nn.Conv2d(256, 256, 3, padding=1), nn.ReLU(inplace=True),
                    nn.AdaptiveAvgPool2d((7, 7))
                )

                self.regressor = nn.Sequential(
                    nn.Flatten(),
                    nn.Linear(256 * 7 * 7, 512), nn.ReLU(), nn.Dropout(0.5),
                    nn.Linear(512, 256), nn.ReLU(), nn.Dropout(0.3),
                    nn.Linear(256, 128), nn.ReLU(),
                    nn.Linear(128, 2)
                )

            def forward(self, x):
                x = self.features(x)
                x = self.regressor(x)
                return x

        return EfficientGeoCNN()


# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
def load_model():
    try:
        # –°–Ω–∞—á–∞–ª–∞ –ø–æ–ø—Ä–æ–±—É–µ–º unified_geo_model.pth
        model_path = 'unified_geo_model.pth'
        if not os.path.exists(model_path):
            # –ï—Å–ª–∏ –Ω–µ—Ç, –ø–æ–ø—Ä–æ–±—É–µ–º final_geo_model.pth
            model_path = 'final_geo_model.pth'
            if not os.path.exists(model_path):
                print("‚ùå –§–∞–π–ª—ã –º–æ–¥–µ–ª–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                return None, None

        print(f"üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏: {model_path}")
        checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)

        # –°–æ–∑–¥–∞–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º—É—é –º–æ–¥–µ–ª—å
        model = create_compatible_model(checkpoint['model_state_dict'])

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞ (–∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ)
        model_dict = model.state_dict()
        pretrained_dict = {}

        loaded_count = 0
        total_count = 0

        for k, v in checkpoint['model_state_dict'].items():
            total_count += 1
            if k in model_dict:
                if model_dict[k].shape == v.shape:
                    pretrained_dict[k] = v
                    loaded_count += 1
                    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω: {k}")
                else:
                    print(f"‚ö†Ô∏è  –†–∞–∑–º–µ—Ä –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç: {k} - {v.shape} vs {model_dict[k].shape}")
            else:
                print(f"‚ùå –°–ª–æ–π –Ω–µ –Ω–∞–π–¥–µ–Ω: {k}")

        if pretrained_dict:
            model_dict.update(pretrained_dict)
            model.load_state_dict(model_dict)
            print(f"üéØ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {loaded_count}/{total_count} —Å–ª–æ–µ–≤")
        else:
            print("‚ö†Ô∏è  –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª—É—á–∞–π–Ω—É—é –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é")

        model.eval()

        print("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")

        # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ scalers
        print("üìä –î–µ—Ç–∞–ª–∏ checkpoint:")
        for key, value in checkpoint.items():
            if 'scaler' in key:
                print(f"   {key}: {value} (shape: {value.shape})")

        return model, checkpoint

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        import traceback
        traceback.print_exc()
        return None, None


model, checkpoint = load_model()


def denormalize_coordinates(normalized_coords, checkpoint):
    """–ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –¥–µ–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç"""
    try:
        # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
        lat_mean = checkpoint['scaler_lat_mean'][0]
        lat_scale = checkpoint['scaler_lat_scale'][0]
        lon_mean = checkpoint['scaler_lon_mean'][0]
        lon_scale = checkpoint['scaler_lon_scale'][0]

        print(f"üîß –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–µ–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏:")
        print(f"   Lat: mean={lat_mean:.6f}, scale={lat_scale:.6f}")
        print(f"   Lon: mean={lon_mean:.6f}, scale={lon_scale:.6f}")
        print(f"   –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã: {normalized_coords}")

        # –î–µ–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è: original = normalized * scale + mean
        lat = normalized_coords[0] * lat_scale + lat_mean
        lon = normalized_coords[1] * lon_scale + lon_mean

        print(f"   –î–µ–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ: lat={lat:.6f}, lon={lon:.6f}")

        return lat, lon

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –¥–µ–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
        return 55.7558, 37.6173


@app.route('/')
def home():
    return '''
    <html>
    <body style="font-family: Arial; text-align: center; padding: 50px;">
        <h1>üéØ –ì–µ–æ–ª–æ–∫–∞—Ü–∏—è –∫–∞–º–µ—Ä—ã</h1>
        <form action="/predict" method="post" enctype="multipart/form-data">
            <input type="file" name="image" accept="image/*" required>
            <button type="submit">–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∫–∞–º–µ—Ä—ã</button>
        </form>
        <p>–°—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–∏: ''' + ('‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞' if model else '‚ùå –ù–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞') + '''</p>
    </body>
    </html>
    '''


@app.route('/predict', methods=['POST'])
def predict():
    if model is None or checkpoint is None:
        return "–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞"

    try:
        file = request.files['image']
        image = Image.open(io.BytesIO(file.read())).convert('RGB')
        image = np.array(image)
        image = cv2.resize(image, (224, 224))
        image = image.astype(np.float32) / 255.0
        image_tensor = torch.from_numpy(image).permute(2, 0, 1).float().unsqueeze(0)

        with torch.no_grad():
            pred_normalized = model(image_tensor).numpy()[0]

        lat, lon = denormalize_coordinates(pred_normalized, checkpoint)

        return f'''
        <html>
        <body style="font-family: Arial; padding: 50px;">
            <h2>üìç –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∫–∞–º–µ—Ä—ã:</h2>
            <p><b>–®–∏—Ä–æ—Ç–∞:</b> {lat:.6f}</p>
            <p><b>–î–æ–ª–≥–æ—Ç–∞:</b> {lon:.6f}</p>
            <p><a href="/">–ù–∞–∑–∞–¥</a></p>
        </body>
        </html>
        '''
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}"


if __name__ == '__main__':
    port = int(os.getenv('PORT', 8080))
    print(f"üöÄ –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –Ω–∞ –ø–æ—Ä—Ç—É {port}")
    app.run(host='0.0.0.0', port=port, debug=False)