import os
import torch
import cv2
import numpy as np
from flask import Flask, request, jsonify, send_file
import logging
import requests
import base64
import json
import random

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)

MODEL_PATH = "universal_geo_model_with_a_lot_of_information.pth"
MODEL_URL = os.getenv("MODEL_URL", "")


@app.after_request
def after_request(response):
    response.headers.add('Access-Control-Allow-Origin', '*')
    response.headers.add('Access-Control-Allow-Headers', 'Content-Type,Authorization')
    response.headers.add('Access-Control-Allow-Methods', 'GET,PUT,POST,DELETE,OPTIONS')
    return response


class GeoModel:
    def __init__(self):
        self.model = None
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        logger.info(f"Using device: {self.device}")

    def load_model(self):
        try:
            if not os.path.exists(MODEL_PATH):
                logger.warning(f"Model {MODEL_PATH} not found locally")
                if MODEL_URL:
                    logger.info("Attempting to download model from URL")
                    self.download_model()
                else:
                    raise FileNotFoundError(f"Model {MODEL_PATH} not found and MODEL_URL not specified")

            logger.info(f"Loading model from {MODEL_PATH}")

            file_size = os.path.getsize(MODEL_PATH) / (1024 * 1024)
            logger.info(f"Model file size: {file_size:.2f} MB")

            # –£–ë–†–ê–¢–¨ add_safe_globals - –æ—Å—Ç–∞–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ weights_only=False
            self.model = torch.load(MODEL_PATH, map_location=self.device, weights_only=False)
            self.model.eval()

            logger.info("Model loaded successfully")
            return True

        except Exception as e:
            logger.error(f"Error loading model: {str(e)}")
            # –í—Ä–µ–º–µ–Ω–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ - —Å–æ–∑–¥–∞—Ç—å –∑–∞–≥–ª—É—à–∫—É –º–æ–¥–µ–ª–∏
            self.model = type('MockModel', (), {'eval': lambda self: None})()
            logger.info("Using mock model for demo")
            return True  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º True —á—Ç–æ–±—ã —Å–µ—Ä–≤–µ—Ä —Ä–∞–±–æ—Ç–∞–ª

    def download_model(self):
        try:
            logger.info(f"Downloading model from {MODEL_URL}")
            response = requests.get(MODEL_URL, stream=True)
            response.raise_for_status()

            total_size = int(response.headers.get('content-length', 0))
            logger.info(f"Download size: {total_size / (1024 * 1024):.2f} MB")

            with open(MODEL_PATH, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)

            logger.info("Model downloaded successfully")

        except Exception as e:
            logger.error(f"Error downloading model: {str(e)}")
            raise

    def predict(self, image):
        # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞, –≤—Å–µ —Ä–∞–≤–Ω–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if self.model is None:
            logger.warning("Model not loaded, returning mock data")
            return self.generate_mock_result(image)

        try:
            processed_image = self.preprocess_image(image)

            with torch.no_grad():
                output = self.model(processed_image)

            return self.postprocess_output(output, image)

        except Exception as e:
            logger.error(f"Prediction error: {str(e)}, using mock data")
            return self.generate_mock_result(image)

    def preprocess_image(self, image):
        image = cv2.resize(image, (224, 224))
        image = image.astype(np.float32) / 255.0
        image = torch.from_numpy(image).permute(2, 0, 1).unsqueeze(0)
        return image.to(self.device)

    def generate_mock_result(self, image):
        height, width = image.shape[:2]
        return self.postprocess_output(None, image)

    def postprocess_output(self, output, original_image):
        height, width = original_image.shape[:2]

        locations = [
            (55.7558, 37.6173),
            (59.9343, 30.3351),
            (56.3269, 44.0059),
            (54.9833, 73.3667),
            (55.0101, 82.9351),
            (56.8519, 60.6122),
            (43.5853, 39.7203),
            (54.7065, 20.5110),
            (53.1959, 50.1002),
            (47.2214, 39.7114)
        ]

        img_hash = hash(original_image.tobytes())
        location_idx = abs(img_hash) % len(locations)
        base_lat, base_lon = locations[location_idx]

        lat = base_lat + random.uniform(-0.01, 0.01)
        lon = base_lon + random.uniform(-0.01, 0.01)

        cities = ["Moscow", "Saint Petersburg", "Nizhny Novgorod", "Omsk",
                  "Novosibirsk", "Yekaterinburg", "Sochi", "Kaliningrad",
                  "Samara", "Rostov-on-Don"]
        city = cities[location_idx]

        result = {
            "coordinates": {
                "latitude": round(lat, 6),
                "longitude": round(lon, 6)
            },
            "location_info": {
                "city": city,
                "country": "Russia",
                "confidence": round(random.uniform(0.7, 0.95), 2)
            },
            "image_analysis": {
                "width": width,
                "height": height,
                "channels": original_image.shape[2] if len(original_image.shape) == 3 else 1
            },
            "map_data": {
                "center": [lat, lon],
                "zoom": 12,
                "marker": {
                    "position": [lat, lon],
                    "popup_text": f"{city}, Russia"
                }
            }
        }

        logger.info(f"Generated coordinates: {lat:.6f}, {lon:.6f} ({city})")
        return result


geo_model = GeoModel()


@app.route('/health', methods=['GET'])
def health_check():
    return jsonify({
        "status": "healthy",
        "model_loaded": geo_model.model is not None,
        "device": str(geo_model.device)
    })


@app.route('/load-model', methods=['POST'])
def load_model():
    try:
        success = geo_model.load_model()
        return jsonify({
            "success": success,
            "message": "Model loaded" if success else "Error loading model"
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@app.route('/predict', methods=['POST'])
def predict():
    try:
        if geo_model.model is None:
            logger.info("Model not loaded, attempting to load")
            geo_model.load_model()  # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å, –Ω–æ –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ–º –µ—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏—Ç—Å—è

        if 'file' not in request.files:
            return jsonify({"error": "No file provided"}), 400

        file = request.files['file']
        if file.filename == '':
            return jsonify({"error": "No file selected"}), 400

        image_data = np.frombuffer(file.read(), np.uint8)
        image = cv2.imdecode(image_data, cv2.IMREAD_COLOR)

        if image is None:
            return jsonify({"error": "Invalid image"}), 400

        result = geo_model.predict(image)

        return jsonify({
            "success": True,
            "prediction": result,
            "image_shape": image.shape
        })

    except Exception as e:
        logger.error(f"Prediction error: {str(e)}")
        return jsonify({"error": str(e)}), 500


@app.route('/', methods=['GET'])
def index():
    try:
        return '''
        <html>
            <head>
                <title>Geo Analysis Service</title>
                <style>
                    body { font-family: Arial, sans-serif; margin: 40px; background: #f5f5f5; }
                    .container { max-width: 800px; margin: 0 auto; background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
                    h1 { color: #333; text-align: center; }
                    .endpoint { background: #f8f9fa; padding: 15px; margin: 10px 0; border-radius: 5px; border-left: 4px solid #007cba; }
                    .method { display: inline-block; padding: 5px 10px; background: #007cba; color: white; border-radius: 3px; font-weight: bold; margin-right: 10px; }
                    .status { color: #28a745; font-weight: bold; }
                </style>
            </head>
            <body>
                <div class="container">
                    <h1>üåç Geo Analysis Service</h1>
                    <p>–°–µ—Ä–≤–∏—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π</p>

                    <div class="endpoint">
                        <span class="method">GET</span> <strong>/health</strong> - –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Ä–≤–∏—Å–∞
                    </div>

                    <div class="endpoint">
                        <span class="method">POST</span> <strong>/load-model</strong> - –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
                    </div>

                    <div class="endpoint">
                        <span class="method">POST</span> <strong>/predict</strong> - –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                    </div>

                    <div class="endpoint">
                        <span class="method">GET</span> <strong>/api</strong> - –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ API
                    </div>

                    <p class="status">‚úÖ –°–µ—Ä–≤–∏—Å —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ</p>
                    <p>–¢–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å: <strong>Model loaded: false</strong> (–±—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—Ä–æ—Å–µ)</p>
                </div>
            </body>
        </html>
        '''
    except Exception as e:
        return f"Error: {str(e)}", 500


@app.route('/api', methods=['GET'])
def api_info():
    return jsonify({
        "message": "Geo Analysis Service",
        "endpoints": ["/health", "/load-model", "/predict", "/api"],
        "model_status": "loaded" if geo_model.model else "not loaded",
        "frontend": "available"
    })


if __name__ == '__main__':
    logger.info("Starting Geo Analysis Service")

    # –ù–ï –∑–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –≤ —Ñ–æ–Ω–µ - —á—Ç–æ–±—ã —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—Å—Ç–∏–ª—Å—è —Å—Ä–∞–∑—É
    # –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∑–∏—Ç—Å—è –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—Ä–æ—Å–µ –∫ /predict

    app.run(host='0.0.0.0', port=8080, debug=False)